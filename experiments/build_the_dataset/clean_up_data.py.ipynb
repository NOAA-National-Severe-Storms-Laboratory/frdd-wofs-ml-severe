{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433d5b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac9b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = '/work/mflora/ML_DATA/DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1abc1a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(879554, 194) (883340, 170)\n",
      "['w_up__ensemble_tracks_3km', 'w_up__ensemble_tracks_9km', 'w_up__ensemble_tracks_15km', 'w_up__ensemble_tracks_30km', 'w_up__filled_tracks_3km', 'w_up__filled_tracks_9km', 'w_up__filled_tracks_15km', 'w_up__filled_tracks_30km', 'w_up__ensemble_probabilities_3km', 'w_up__ensemble_probabilities_9km', 'w_up__ensemble_probabilities_15km', 'w_up__ensemble_probabilities_30km', 'xlat_3km', 'xlat_9km', 'xlat_15km', 'xlat_30km', 'xlon_3km', 'xlon_9km', 'xlon_15km', 'xlon_30km']\n",
      "Saving /work/mflora/ML_DATA/DATA/new_wofs_ml_severe__first_hour__data.feather...\n",
      "Saving /work/mflora/ML_DATA/DATA/new_wofs_ml_severe__first_hour__baseline_data.feather...\n",
      "(1240542, 194) (1245385, 170)\n",
      "['w_up__ensemble_tracks_3km', 'w_up__ensemble_tracks_9km', 'w_up__ensemble_tracks_15km', 'w_up__ensemble_tracks_30km', 'w_up__filled_tracks_3km', 'w_up__filled_tracks_9km', 'w_up__filled_tracks_15km', 'w_up__filled_tracks_30km', 'w_up__ensemble_probabilities_3km', 'w_up__ensemble_probabilities_9km', 'w_up__ensemble_probabilities_15km', 'w_up__ensemble_probabilities_30km', 'xlat_3km', 'xlat_9km', 'xlat_15km', 'xlat_30km', 'xlon_3km', 'xlon_9km', 'xlon_15km', 'xlon_30km']\n",
      "Saving /work/mflora/ML_DATA/DATA/new_wofs_ml_severe__second_hour__data.feather...\n",
      "Saving /work/mflora/ML_DATA/DATA/new_wofs_ml_severe__second_hour__baseline_data.feather...\n"
     ]
    }
   ],
   "source": [
    "# Unsure of the exact cause, but there were extra columns from the \n",
    "# ensemble storm track files. Additionally, there were nan values \n",
    "# as some target values (but onyl ~3800 examples). As a temporary \n",
    "# fix, I'm just going to delete those columns and rows. \n",
    "for time in ['first_hour', 'second_hour']:\n",
    "    path = join(basePath, f'wofs_ml_severe__{time}__data.feather')\n",
    "    df = pd.read_feather(path)\n",
    "\n",
    "    baseline_path = join(basePath, f'wofs_ml_severe__{time}__baseline_data.feather')\n",
    "    baseline_df = pd.read_feather(baseline_path)\n",
    "    \n",
    "    print(df.shape, baseline_df.shape)\n",
    "    \n",
    "    columns = list(df.columns)\n",
    "    columns_to_drop = columns[columns.index('w_up__ensemble_tracks_3km'):-1]\n",
    "    print(columns_to_drop)\n",
    "    columns_to_keep = [c for c in columns if c not in columns_to_drop]\n",
    "    \n",
    "    # Keep good columns\n",
    "    df_new = df[columns_to_keep]\n",
    "    # Keep nan value targets\n",
    "    inds = ~np.isnan(baseline_df['hail_severe_3km'].values)\n",
    "    \n",
    "    #df_new = df_new.iloc[inds, :]\n",
    "    \n",
    "    new_baseline_df = baseline_df.iloc[inds,:]\n",
    "    \n",
    "    # reset the indices.\n",
    "    df_new.reset_index(inplace=True, drop=True)\n",
    "    new_baseline_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    for out_path, df_ in zip([path, baseline_path], [df_new, new_baseline_df]):\n",
    "        new_path = out_path.replace('wofs', 'new_wofs')\n",
    "        print(f'Saving {new_path}...')\n",
    "        df_.to_feather(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9269497",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 'first_hour'\n",
    "path = join(basePath, f'new_wofs_ml_severe__{time}__data.feather')\n",
    "df = pd.read_feather(path)\n",
    "\n",
    "baseline_path = join(basePath, f'new_wofs_ml_severe__{time}__baseline_data.feather')\n",
    "baseline_df = pd.read_feather(baseline_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92385008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(879554, 174) (879554, 170)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape, baseline_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedde46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
