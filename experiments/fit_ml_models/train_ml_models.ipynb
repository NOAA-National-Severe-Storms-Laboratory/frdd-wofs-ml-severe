{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee9921f",
   "metadata": {},
   "source": [
    "## Train the Real-Time ML Models \n",
    "\n",
    "The real-time ML models are trained on all available warm season cases (2017-current). \n",
    "The following models are trained in this script: \n",
    "1. Severe Hail \n",
    "2. Severe Wind \n",
    "3. Tornado \n",
    "4. Sig. Hail\n",
    "5. Sig. Wind \n",
    "6. Sig. Tornado\n",
    "7. All-severe \n",
    "8. All-sig-severe \n",
    "\n",
    "The model classes include: \n",
    "1. LogisticRegression\n",
    "2. HistGradientBoosting \n",
    "3. RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e87952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' usage: stdbuf -oL python -u train_ml_models.py > & log_train_models & '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" usage: stdbuf -oL python -u train_ml_models.py > & log_train_models & \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c82c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The custom classifier \n",
    "import sys\n",
    "sys.path.append('/home/monte.flora/python_packages/wofs_ml_severe')\n",
    "sys.path.insert(0, '/home/monte.flora/python_packages/ml_workflow')\n",
    "\n",
    "from ml_workflow import TunedEstimator \n",
    "from wofs_ml_severe import load_ml_data\n",
    "from wofs_ml_severe.common.emailer import Emailer \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sklearn \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from os.path import join, exists\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "\n",
    "import sklearn.exceptions\n",
    "os.environ[\"PYTHONPATH\"] = os.path.dirname(sklearn.exceptions.__file__)\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore::exceptions.ConvergenceWarning:sklearn.svm.base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a440d265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(estimator, X, y):\n",
    "    pred = estimator.predict_proba(X)[:,1]\n",
    "    return 1.0 - average_precision_score(y, pred)\n",
    "\n",
    "def dates_to_groups(dates, n_splits=5): \n",
    "    \"\"\"Separated different dates into a set of groups based on n_splits\"\"\"\n",
    "    df = dates.copy()\n",
    "    df = df.to_frame()\n",
    "    \n",
    "    unique_dates = np.unique(dates.values)\n",
    "    np.random.shuffle(unique_dates)\n",
    "\n",
    "    df['groups'] = np.zeros(len(dates))\n",
    "    for i, group in enumerate(np.array_split(unique_dates, n_splits)):\n",
    "        df.loc[dates.isin(group), 'groups'] = i+1 \n",
    "        \n",
    "    groups = df.groups.values\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def get_search_space(model_name):\n",
    "    if model_name == 'RandomForest':\n",
    "        model = RandomForestClassifier(n_jobs=40, random_state=123)\n",
    "        n_features = X.shape[1]\n",
    "        search_space = {\n",
    "                'criterion' : ['gini', 'entropy', 'log_loss'],\n",
    "                'n_estimators' : [100, 150, 200, 300], \n",
    "                'max_depth' : [2,5, 10, 15, 25, 40, None],\n",
    "                'min_samples_split' : [2,5, 10,15,40],\n",
    "                'min_samples_leaf':  [4,5,8,10,15,20,25,50],\n",
    "                'max_features': list(np.arange(1, n_features)),\n",
    "                'class_weight' : ['balanced', None],\n",
    "                } \n",
    "        n_jobs = 1\n",
    "    \n",
    "    elif model_name == 'LogisticRegression':\n",
    "        model = LogisticRegression(penalty='l2', random_state=123)\n",
    "        search_space = {\n",
    "                'C': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0],\n",
    "                'class_weight' : [None, 'balanced']\n",
    "                }\n",
    "        n_jobs = 5\n",
    "    \n",
    "    elif model_name == 'XGBoost':\n",
    "        n_jobs=1\n",
    "        model = XGBClassifier(objective= 'binary:logistic', seed=123, \n",
    "                          tree_method='gpu_hist', gpu_id=0)\n",
    "    \n",
    "        search_space = {\n",
    "        'n_estimators' : [50, 100, 150, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.5],\n",
    "        'max_depth': [3,5,6,10,15,20],\n",
    "        'subsample': list(np.arange(0.5, 1.0, 0.1)),\n",
    "        'colsample_bytree': list(np.arange(0.5, 1.0, 0.1)),\n",
    "        'gamma': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10., 100.],\n",
    "        'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10., 100.],\n",
    "        'lambda': [0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10., 100.],\n",
    "        'sampling_method' : ['uniform', 'gradient_based'],\n",
    "        'min_child_weight' : list(np.arange(1, 8, 1, dtype=int)),    \n",
    "    }\n",
    "        \n",
    "    return model, search_space, n_jobs \n",
    "\n",
    "\n",
    "def get_feature_type(X, categorical_features):\n",
    "    \n",
    "    # Define the categorical features for the pre-processing pipeline. \n",
    "    numeric_features = [i for i in range(len(X.columns))]\n",
    "    categorical_features = [list(X.columns).index(f) for f in categorical_features]\n",
    "    _ = [numeric_features.remove(i) for i in categorical_features]\n",
    "    \n",
    "    return categorical_features, numeric_features \n",
    "\n",
    "\n",
    "\n",
    "def get_target_str(target):\n",
    "    # Initialize the kwargs for the hyperparameter optimization.\n",
    "    if isinstance(target, list):\n",
    "        if 'sig_severe' in target[0]:\n",
    "            target = 'all_sig_severe'\n",
    "        else:\n",
    "            target = 'all_severe'\n",
    "   \n",
    "    return target \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63e11fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training a new model....\n",
      "Target: ['wind_severe_0km', 'hail_severe_0km', 'tornado_severe_0km'] \n",
      "          Model Name : LogisticRegression \n",
      "          Lead Time: first_hour \n",
      "          Resample: under \n",
      "          Mode: realtime\n",
      "\n",
      "Only keeping warm season cases for the official training!\n",
      " 40%|██████████████████████████████████▍                                                   | 2/5 [01:22<02:03, 41.02s/trial, best loss: 0.4854968886448973]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Invalid -W option ignored: invalid module name: 'exceptions'\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Invalid -W option ignored: invalid module name: 'exceptions'\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Invalid -W option ignored: invalid module name: 'exceptions'\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Invalid -W option ignored: invalid module name: 'exceptions'\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "Invalid -W option ignored: invalid module name: 'exceptions'\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/work/mflora/miniconda3/envs/ml/lib/python3.8/site-packages/daal4py/sklearn/linear_model/logistic_path.py:548: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "OUT_PATH = '/work/mflora/ML_DATA/NEW_ML_MODELS'\n",
    "\n",
    "target_cols = [['wind_severe_0km', 'hail_severe_0km', 'tornado_severe_0km']]\n",
    "model_names = ['LogisticRegression']\n",
    "resampling = ['under',]\n",
    "times = ['first_hour']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "target_cols = ['wind_severe_0km', 'hail_severe_0km', 'tornado_severe_0km', \n",
    "               ['wind_severe_0km', 'hail_severe_0km', 'tornado_severe_0km'],\n",
    "               'wind_sig_severe_0km', 'hail_sig_severe_0km', 'tornado_sig_severe_0km',\n",
    "               ['wind_sig_severe_0km', 'hail_sig_severe_0km', 'tornado_sig_severe_0km']]\n",
    "model_names = ['XGBoost', 'LogisticRegression', 'RandomForestClassifier']\n",
    "resampling = ['under', None]\n",
    "times = ['first_hour', 'second_hour', 'third_hour', 'fourth_hour']\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# If 'training', it will load the data with the original training dates from Flora et al. (2021, MWR)\n",
    "modes = [None, 'training']\n",
    "\n",
    "# If True, existing files will be overwritten; setting to False is useful when the scripts\n",
    "# fails to finish and I don't want to redo stuff. \n",
    "overwrite = False\n",
    "\n",
    "emailer = Emailer()\n",
    "\n",
    "for target, model_name, time, resample, mode in itertools.product(target_cols, \n",
    "                                                            model_names,\n",
    "                                                            times,\n",
    "                                                            resampling, \n",
    "                                                                  modes): \n",
    "    \n",
    "    retro_str = 'retro' if mode == 'training' else 'realtime'\n",
    "    \n",
    "    target_str = get_target_str(target)\n",
    "    \n",
    "    fname = join(OUT_PATH, \n",
    "                 f'{model_name}_{target_str}_{resample}_{time}_{retro_str}.joblib')\n",
    "    \n",
    "    if not overwrite:\n",
    "        if exists(fname):\n",
    "            continue \n",
    "            \n",
    "    if target_str in ['all_severe', 'all_sig_severe'] and retro_str =='retro':\n",
    "        continue \n",
    "            \n",
    "    \n",
    "    print('\\nTraining a new model....')\n",
    "    subject = f\"\"\"Target: {target} \n",
    "          Model Name : {model_name} \n",
    "          Lead Time: {time} \n",
    "          Resample: {resample} \n",
    "          Mode: {retro_str}\\n\"\"\"\n",
    "    print(subject)\n",
    "    \n",
    "    start_time = emailer.get_start_time()\n",
    "\n",
    "    # Load the data. Using the run dates, we can group the data into \n",
    "    # 5 cross-validation folds, which will be used for hyperparameter optimization\n",
    "    # and training the calibration model. \n",
    "    X, y, metadata = load_ml_data(target_col=target, \n",
    "                                  lead_time=time,\n",
    "                                  mode=mode,\n",
    "                                 )\n",
    "    \n",
    "    dates = metadata['Run Date']\n",
    "    groups = dates_to_groups(dates, n_splits=5)\n",
    "    \n",
    "    model, search_space, n_jobs = get_search_space(model_name)\n",
    "    \n",
    "    categorical_features, numeric_features = get_feature_type(X, categorical_features=['Initialization Time'])\n",
    "    \n",
    "    # Initialize the cross-validation groups \n",
    "    cv = list(GroupKFold(n_splits=5).split(X,y,groups))\n",
    "    \n",
    "    output_fname = join(OUT_PATH, 'hyperopt_results', \n",
    "                        f'{model_name}_{target_str}_{resample}_{time}_{retro_str}.feather')\n",
    "    \n",
    "    hyperopt_kwargs = {'search_space' : search_space, \n",
    "                   'optimizer' : 'tpe', \n",
    "                   'max_evals' : 100, \n",
    "                   'patience' : 40, \n",
    "                  'scorer' : scorer, \n",
    "                  'n_jobs' : n_jobs, \n",
    "                  'cv' : cv, \n",
    "                  'output_fname' : output_fname \n",
    "                      }\n",
    "    \n",
    "    # Initialize the kwargs for the Pipeline. \n",
    "    pipeline_kwargs={'imputer' : 'simple', \n",
    "                     'resample': resample, \n",
    "                     'scaler': 'standard', \n",
    "                     'numeric_features' : numeric_features, \n",
    "                     'categorical_features' :  categorical_features}\n",
    "    \n",
    "    # Initialize the kwargs for the calibration model. \n",
    "    calibration_cv_kwargs = {'method' : 'isotonic', 'ensemble' : False, \n",
    "                         'cv' : cv, 'n_jobs': n_jobs}\n",
    "\n",
    "    # Fit the model and save it. \n",
    "    estimator = TunedEstimator(model, pipeline_kwargs, hyperopt_kwargs, calibration_cv_kwargs)\n",
    "    \n",
    "    if hasattr(y, 'values'):\n",
    "        y = y.values\n",
    "    \n",
    "    estimator.fit(X, y, groups)\n",
    "\n",
    "    estimator.save(fname)\n",
    "    \n",
    "    emailer.send_email(subject, start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
