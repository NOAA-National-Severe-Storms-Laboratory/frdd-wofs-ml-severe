{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e048541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup_file: /home/monte.flora/python_packages/WoF_post/wofs/data/psadilookup.dat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# The custom classifier \n",
    "import sys, os\n",
    "sys.path.insert(0, '/home/monte.flora/python_packages/wofs_ml_severe')\n",
    "sys.path.insert(0, '/home/monte.flora/python_packages/ml_workflow')\n",
    "sys.path.insert(0, '/home/monte.flora/python_packages/WoF_post')\n",
    "\n",
    "from wofs.ml.load_ml_models import load_ml_model\n",
    "from wofs.post.utils import load_yaml\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from ml_workflow.weighted_average_classifier import WeightedAverageClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from ml_workflow.ml_methods import brier_skill_score\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c552dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def dates_to_groups(dates, n_splits=5): \n",
    "    \"\"\"Separated different dates into a set of groups based on n_splits\"\"\"\n",
    "    df = dates.copy()\n",
    "    df = df.to_frame()\n",
    "    \n",
    "    unique_dates = np.unique(dates.values)\n",
    "    np.random.shuffle(unique_dates)\n",
    "\n",
    "    df['groups'] = np.zeros(len(dates))\n",
    "    for i, group in enumerate(np.array_split(unique_dates, n_splits)):\n",
    "        df.loc[dates.isin(group), 'groups'] = i+1 \n",
    "        \n",
    "    groups = df.groups.values\n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f1551",
   "metadata": {},
   "source": [
    "### Fit the Official Weighted Average Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d7340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_best_val_score(model_name, target, time, \n",
    "                          resample = None, retro_str = 'realtime'): \n",
    "    \"\"\"Return the best cross-validation score from the hyperparam tuning. \"\"\"\n",
    "    BASE_PATH =  '/work/mflora/ML_DATA/NEW_ML_MODELS/hyperopt_results'\n",
    "    \n",
    "    fname = os.path.join(BASE_PATH, \n",
    "                    f'{model_name}_{target}_{resample}_{time}_{retro_str}.feather')\n",
    "\n",
    "    df = pd.read_feather(fname)\n",
    "    ascending = False if model_name == \"LogisticRegression\" else True\n",
    "    df_sorted = df.sort_values(by='loss', ascending=ascending)['loss']\n",
    "    \n",
    "    df_sorted.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    val = df_sorted[0]\n",
    "    \n",
    "    if val < 0:\n",
    "        return -val\n",
    "    else:\n",
    "        return val \n",
    "    \n",
    "def get_weights(model_names, time, target):\n",
    "    \"\"\"Compute the weights for the weighted averaging.\"\"\"\n",
    "    scores = [return_best_val_score(model_name, target, time) for model_name in model_names]\n",
    "    total_scores = np.sum(scores)\n",
    "    return scores / total_scores \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e48a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup_file: /home/monte.flora/python_packages/WoF_post/wofs/data/psadilookup.dat\n",
      "\n",
      " Hazard: WIND_SEVERE_0KM....Time : FIRST_HOUR\n",
      "Classifier Weights: [(0.5038458988384041, 'LogisticRegression'), (0.496154101161596, 'XGBoost')]\n",
      "\n",
      " Hazard: WIND_SEVERE_0KM....Time : SECOND_HOUR\n",
      "Classifier Weights: [(0.5163010844857072, 'LogisticRegression'), (0.48369891551429284, 'XGBoost')]\n",
      "\n",
      " Hazard: HAIL_SEVERE_0KM....Time : FIRST_HOUR\n",
      "Classifier Weights: [(0.49320022709895833, 'LogisticRegression'), (0.5067997729010416, 'XGBoost')]\n",
      "\n",
      " Hazard: HAIL_SEVERE_0KM....Time : SECOND_HOUR\n",
      "Classifier Weights: [(0.49559241368089957, 'LogisticRegression'), (0.5044075863191004, 'XGBoost')]\n",
      "\n",
      " Hazard: TORNADO_SEVERE_0KM....Time : FIRST_HOUR\n",
      "Classifier Weights: [(0.48828552326542174, 'LogisticRegression'), (0.5117144767345784, 'XGBoost')]\n",
      "\n",
      " Hazard: TORNADO_SEVERE_0KM....Time : SECOND_HOUR\n",
      "Classifier Weights: [(0.4799149173674372, 'LogisticRegression'), (0.5200850826325629, 'XGBoost')]\n",
      "\n",
      " Hazard: ALL_SEVERE....Time : FIRST_HOUR\n",
      "Classifier Weights: [(0.49786505313540586, 'LogisticRegression'), (0.5021349468645941, 'XGBoost')]\n",
      "\n",
      " Hazard: ALL_SEVERE....Time : SECOND_HOUR\n",
      "Classifier Weights: [(0.49704891823764036, 'LogisticRegression'), (0.5029510817623597, 'XGBoost')]\n",
      "\n",
      " Hazard: ALL_SIG_SEVERE....Time : FIRST_HOUR\n",
      "Classifier Weights: [(0.5167731669226003, 'LogisticRegression'), (0.4832268330773998, 'XGBoost')]\n",
      "\n",
      " Hazard: ALL_SIG_SEVERE....Time : SECOND_HOUR\n",
      "Classifier Weights: [(0.47860181085556835, 'LogisticRegression'), (0.5213981891444316, 'XGBoost')]\n"
     ]
    }
   ],
   "source": [
    "from wofs_ml_severe.io.load_ml_models import load_ml_model\n",
    "\n",
    "times = ['first_hour', 'second_hour']\n",
    "config_path = '/home/monte.flora/python_packages/wofs_ml_severe/wofs_ml_severe/conf/ml_config_realtime.yml'\n",
    "targets = ['wind_severe_0km', 'hail_severe_0km', 'tornado_severe_0km', 'all_severe', 'all_sig_severe']\n",
    "model_names = ['LogisticRegression', 'XGBoost'] \n",
    "\n",
    "ml_config = load_yaml(config_path)\n",
    "OUT_PATH = '/work/mflora/ML_DATA/NEW_ML_MODELS'  \n",
    "retro_str = 'realtime'\n",
    "    \n",
    "for target, time in itertools.product(targets, times):\n",
    "    print(f'\\n Hazard: {target.upper()}....Time : {time.upper()}')\n",
    "    estimators = [] \n",
    "    for model_name in model_names: \n",
    "        parameters = {\n",
    "                'target' : target,\n",
    "                'time' : time, \n",
    "                'drop_opt' : '',\n",
    "                'model_name' : model_name,\n",
    "                'ml_config' : ml_config,\n",
    "            }\n",
    "    \n",
    "    \n",
    "        model_dict = load_ml_model(**parameters)\n",
    "        model = model_dict['model']\n",
    "        features = model_dict['X'].columns\n",
    "\n",
    "        estimators.append(model)\n",
    "\n",
    "    # Fit the WeightedAverageClassifier\n",
    "    weights = get_weights(model_names, time, target)\n",
    "    clf = WeightedAverageClassifier(estimators,  weights=weights)\n",
    "    clf.features = features\n",
    "    clf.save(os.path.join(OUT_PATH, f'Average_{target}_None_{time}_{retro_str}.joblib'))\n",
    "    \n",
    "    print(f'Classifier Weights: {list(zip(clf.weights_, model_names))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a98154f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeightedAverageClassifier(estimators=[CalibratedClassifierCV(base_estimator=Pipeline(steps=[('imputer',\n",
       "                                                                                             SimpleImputer(strategy='median')),\n",
       "                                                                                            ('scaler',\n",
       "                                                                                             StandardScaler()),\n",
       "                                                                                            ('model',\n",
       "                                                                                             LogisticRegression(C=0.01,\n",
       "                                                                                                                l1_ratio=1.0,\n",
       "                                                                                                                penalty='elasticnet',\n",
       "                                                                                                                random_state=123,\n",
       "                                                                                                                solver='saga'))]),\n",
       "                                                             cv='None',\n",
       "                                                             ensemble=False,\n",
       "                                                             method='isotonic',\n",
       "                                                             n_jobs=84),\n",
       "                                      CalibratedClassifierCV(base...\n",
       "                                                                                                           interaction_constraints=None,\n",
       "                                                                                                           lambda=1e-05,\n",
       "                                                                                                           learning_rate=0.1,\n",
       "                                                                                                           max_bin=None,\n",
       "                                                                                                           max_cat_threshold=None,\n",
       "                                                                                                           max_cat_to_onehot=None,\n",
       "                                                                                                           max_delta_step=None,\n",
       "                                                                                                           max_depth=5,\n",
       "                                                                                                           max_leaves=None,\n",
       "                                                                                                           min_child_weight=3,\n",
       "                                                                                                           missing=nan,\n",
       "                                                                                                           monotone_constraints=None,\n",
       "                                                                                                           n_estimators=300,\n",
       "                                                                                                           n_jobs=None,\n",
       "                                                                                                           num_parallel_tree=None, ...))]),\n",
       "                                                             cv='None',\n",
       "                                                             ensemble=False,\n",
       "                                                             method='isotonic',\n",
       "                                                             n_jobs=1)],\n",
       "                          weights=array([0.47860181, 0.52139819]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we can successfully load the weighted average classifier. \n",
    "parameters = {\n",
    "                'target' : target,\n",
    "                'time' : time, \n",
    "                'drop_opt' : '',\n",
    "                'model_name' : 'Average',\n",
    "                'ml_config' : ml_config,\n",
    "            }\n",
    "    \n",
    "model_dict = load_ml_model(**parameters)\n",
    "model_dict['features']\n",
    "model_dict['model']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
