{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516eb609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/monte.flora/python_packages/scikit-explain/')\n",
    "sys.path.append('/home/monte.flora/python_packages/master/ml_workflow')\n",
    "sys.path.append('/work/mflora/ROAD_SURFACE')\n",
    "import skexplain\n",
    "from os.path import join\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from display_names import to_readable_names, get_units, to_color\n",
    "\n",
    "from probsr_config import PREDICTOR_COLUMNS, FIGURE_MAPPINGS, COLOR_DICT\n",
    "from skexplain.common.importance_utils import to_skexplain_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a44dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "def to_xarray(shap_data, estimator_name, feature_names=None):\n",
    "    dataset={}\n",
    "    \n",
    "    shap_values = shap_data['shap_values']\n",
    "    bias = shap_data['bias']\n",
    "    \n",
    "    dataset[f'shap_values__{estimator_name}'] = (['n_examples', 'n_features'], shap_values)\n",
    "    dataset[f'bias__{estimator_name}'] = (['n_examples'], bias.astype(np.float64))\n",
    "    dataset['X'] = (['n_examples', 'n_features'], shap_data['X'])\n",
    "    dataset['y'] = (['n_examples'], shap_data['targets'])\n",
    "    \n",
    "    ds = xr.Dataset(dataset)\n",
    "    #ds.attrs['features'] = feature_names\n",
    "    \n",
    "    return ds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3526e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazard = 'tornado'\n",
    "\n",
    "# Load the WoFS data. \n",
    "base_path = '/work/mflora/ML_DATA/DATA'\n",
    "data_path = join(base_path, f'original_first_hour_training_matched_to_{hazard}_0km_data.feather')\n",
    "df = pd.read_feather(data_path)\n",
    "\n",
    "\n",
    "# Load the WoFS-ML-Severe Models\n",
    "base_path = '/work/mflora/ML_DATA/MODEL_SAVES'\n",
    "model_name = 'LogisticRegression'\n",
    "model_paths = glob(join(base_path, f'{model_name}_first_hour_{hazard}*'))\n",
    "model_path = [m for m in model_paths if 'manual' not in m][0]\n",
    "model_data = joblib.load(model_path)\n",
    "\n",
    "model = model_data['model']\n",
    "feature_names = model_data['features']\n",
    "\n",
    "X = df[feature_names].astype(float)\n",
    "y = df[f'matched_to_{hazard}_0km'].astype(float)\n",
    "\n",
    "\n",
    "all_features = df.columns\n",
    "display_feature_names = {f : to_readable_names(f) for f in all_features}\n",
    "feature_colors = {f : to_color(f) for f in all_features}\n",
    "\n",
    "feature_colors = {**feature_colors, **COLOR_DICT}\n",
    "display_feature_names = {**display_feature_names, **FIGURE_MAPPINGS}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df2bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = skexplain.ExplainToolkit(X=X,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ff2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward singlepass, forward multipass, coefs/gini, SHAP \n",
    "base_path = '/work/mflora/ML_DATA/'\n",
    "\n",
    "methods = []\n",
    "results = [] \n",
    "names = []\n",
    "\n",
    "for hazard in ['tornado', 'severe_hail', 'severe_wind', 'road_surface']:\n",
    "    if hazard == 'road_surface':\n",
    "        name = 'Random Forest'\n",
    "    else:\n",
    "        name = 'LogisticRegression'\n",
    "    \n",
    "    # permutation results\n",
    "    if hazard == 'road_surface': \n",
    "        basePath = '/work/mflora/ROAD_SURFACE'\n",
    "        bsp_fname = join(basePath,'permutation_importance', f'perm_imp_original_backward.nc')\n",
    "        fmp_fname = join(basePath,'permutation_importance', f'perm_imp_original_forward.nc')\n",
    "    else:    \n",
    "        path = join(base_path, 'permutation_importance')\n",
    "        bsp_fname = join(path, f'permutation_importance_{hazard}_first_hour_training_norm_aupdcbackward.nc' )\n",
    "        fmp_fname = join(path, f'permutation_importance_{hazard}_first_hour_training_norm_aupdcforward.nc' )   \n",
    "\n",
    "    bsp = explainer.load(bsp_fname)\n",
    "    fmp = explainer.load(fmp_fname)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Backward singlepass and forward multipass: original_score - permuted score\n",
    "    original_score = bsp[f'original_score__{name}'].values\n",
    "    scores = original_score - bsp[f'singlepass_scores__{name}'].values\n",
    "    bsp[f'singlepass_scores__{name}'] = (['n_vars_singlepass', 'n_permute'], scores)\n",
    "    \n",
    "    original_score = fmp[f'original_score__{name}'].values\n",
    "    scores = original_score - fmp[f'multipass_scores__{name}'].values\n",
    "    fmp[f'multipass_scores__{name}'] = (['n_vars_multipass', 'n_permute'], scores)\n",
    "\n",
    "    if hazard == 'road_surface':\n",
    "        methods.extend(['singlepass', 'multipass', 'gini', 'shap_sum'])\n",
    "        # load the random forest\n",
    "        rf = joblib.load(join(basePath, 'JTTI_ProbSR_RandomForest.pkl'))\n",
    "        gini_values = rf.feature_importances_\n",
    "        gini_rank = to_skexplain_importance(gini_values,\n",
    "                                       estimator_name='Random Forest', \n",
    "                                       feature_names=PREDICTOR_COLUMNS, \n",
    "                                         method = 'gini')\n",
    "        \n",
    "    else:\n",
    "        methods.extend(['singlepass', 'multipass', 'coefs', 'shap_sum'])\n",
    "        coefs = model.base_estimator.named_steps['model'].coef_[0]\n",
    "        coef_rank = to_skexplain_importance(coefs,\n",
    "                                       estimator_name=name, \n",
    "                                       feature_names=X.columns, \n",
    "                                        method = 'coefs')\n",
    "\n",
    "    # shap results\n",
    "    if hazard == 'road_surface':\n",
    "        fname = join(basePath,'shap_results', 'shap_rf_original.nc')\n",
    "    else:\n",
    "        fname = join(base_path, 'SHAP_VALUES', f'shap_values_LogisticRegression_{hazard}_first_hour.pkl')\n",
    "    \n",
    "    with open(fname, 'rb') as f:\n",
    "        shap_data = pickle.load(f)\n",
    "        shap_vals = shap_data['shap_values']\n",
    "    \n",
    "    shap_rank = to_skexplain_importance(shap_vals, \n",
    "                                      estimator_name=name, \n",
    "                                      feature_names=X.columns, \n",
    "                                      method ='shap_sum', )\n",
    "\n",
    "    if hazard == 'road_surface':\n",
    "        results.extend([bsp, fmp, gini_rank, shap_rank])\n",
    "    else:\n",
    "        results.extend([bsp, fmp, coef_rank, shap_rank])\n",
    "    \n",
    "    names.extend([name]*4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074f6ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for ds,m, name in zip(results, methods, names):\n",
    "    imp = ds[f'{m}_scores__{name}'].values\n",
    "    imp[imp==0] = 0.000001\n",
    "    imp_norm = imp/ (np.percentile(imp, 99) - np.percentile(imp, 1))\n",
    "    ds[f'{m}_scores__{name}'] = ([f'n_vars_{m}', 'n_permute'], imp_norm)\n",
    "    data.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cc64208",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "xlabels = ['Backward\\nSinglepass','Forward\\nMultipass','Coefs.','SHAP']*3\n",
    "\n",
    "xlabels += ['Backward\\nSinglepass','Forward\\nMultipass','Gini','SHAP']\n",
    "\n",
    "\n",
    "panels = [(m, n) for m, n in zip(methods, names)]\n",
    "fig = explainer.plot_importance(data=data, panels=panels, \n",
    "                                num_vars_to_plot=10, \n",
    "                                display_feature_names=display_feature_names,\n",
    "                                feature_colors=feature_colors,\n",
    "                                plot_correlated_features=False, \n",
    "                                n_columns=4,\n",
    "                                xlabels = xlabels,\n",
    "                                ylabels = ['Tornado', 'Hail', 'Wind', \"Road Surface\"],\n",
    "                                figsize=(12, 12), \n",
    "                                base_font_size= 12,\n",
    "                                wspace=1.0\n",
    "                               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
