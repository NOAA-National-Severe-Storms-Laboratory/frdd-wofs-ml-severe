{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8aaade6",
   "metadata": {},
   "source": [
    "### Explain OverConfident Tornado Predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc06aa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# The custom classifier \n",
    "import sys, os\n",
    "sys.path.insert(0, '/home/monte.flora/python_packages/WoF_post')\n",
    "sys.path.insert(0, '/home/monte.flora/python_packages/ml_workflow')\n",
    "sys.path.insert(0, '/home/monte.flora/python_packages/wofs_ml_severe')\n",
    "\n",
    "from ml_workflow import TunedEstimator \n",
    "from wofs_ml_severe import load_ml_data\n",
    "from wofs_ml_severe.io.load_ml_models import load_ml_model\n",
    "from wofs.post.utils import load_yaml\n",
    "from wofs_ml_severe.common.util import get_target_str, fix_data\n",
    "from display_names import to_display_name, to_units\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import joblib\n",
    "\n",
    "import shap \n",
    "import skexplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596d0818",
   "metadata": {},
   "outputs": [],
   "source": [
    "retro = False\n",
    "target = 'tornado_severe_0km'\n",
    "file_log = 'removed_features_ls_loss'\n",
    "lead_time = 'first_hour'\n",
    "resample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c07d5337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tornado\n",
      "Loading /work/mflora/ML_DATA/NEW_ML_MODELS/LogisticRegression_tornado_severe_0km_None_first_hour_realtime__removed_features_ls_loss.joblib...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/work/mflora/ML_DATA/NEW_ML_MODELS/LogisticRegression_tornado_severe_0km_None_first_hour_realtime__removed_features_ls_loss.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 27\u001b[0m\n\u001b[1;32m     15\u001b[0m ml_config \u001b[38;5;241m=\u001b[39m load_yaml(\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/monte.flora/python_packages/wofs_ml_severe/wofs_ml_severe/conf/ml_config_retro.yml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     19\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m : target,\n\u001b[1;32m     20\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m : lead_time, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresample\u001b[39m\u001b[38;5;124m'\u001b[39m : resample\n\u001b[1;32m     25\u001b[0m             }\n\u001b[0;32m---> 27\u001b[0m model_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_ml_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretro\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m model \u001b[38;5;241m=\u001b[39m model_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     29\u001b[0m X_train \u001b[38;5;241m=\u001b[39m model_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/python_packages/wofs_ml_severe/wofs_ml_severe/io/load_ml_models.py:36\u001b[0m, in \u001b[0;36mload_ml_model\u001b[0;34m(retro, **parameters)\u001b[0m\n\u001b[1;32m     32\u001b[0m     model_fname \u001b[38;5;241m=\u001b[39m model_fname\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_log\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjoin(PATH,\u001b[38;5;250m \u001b[39mmodel_fname)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_fname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/work/mflora/miniconda3/envs/wofs_post/lib/python3.8/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/work/mflora/ML_DATA/NEW_ML_MODELS/LogisticRegression_tornado_severe_0km_None_first_hour_realtime__removed_features_ls_loss.joblib'"
     ]
    }
   ],
   "source": [
    "# Load the data. \n",
    "mode = 'testing'\n",
    "X_test, y_test, metadata = load_ml_data(target_col=target, \n",
    "                              lead_time=lead_time,\n",
    "                              mode=mode,\n",
    "                              base_path = '/work/mflora/ML_DATA/DATA/',\n",
    "                            alter_init_times=True, \n",
    "                                 )\n",
    "X_test = fix_data(X_test)\n",
    "    \n",
    "target_str = get_target_str(target)\n",
    "    \n",
    "print(target_str)\n",
    "# Load the ML models. \n",
    "ml_config = load_yaml(\n",
    "    '/home/monte.flora/python_packages/wofs_ml_severe/wofs_ml_severe/conf/ml_config_retro.yml')\n",
    "\n",
    "parameters = {\n",
    "                'target' : target,\n",
    "                'time' : lead_time, \n",
    "                'model_name' : 'LogisticRegression',\n",
    "                'ml_config' : ml_config,\n",
    "                'file_log'  : file_log,\n",
    "                'resample' : resample\n",
    "            }\n",
    "\n",
    "model_dict = load_ml_model(retro, **parameters)\n",
    "model = model_dict['model']\n",
    "X_train = model_dict['X']\n",
    "features = X_train.columns\n",
    "\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e91e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As stated above, the masker handles the missing features. In this case, we are using correlations \n",
    "# in the dataset to determine the feature groupings. These groups of features are remove or added into \n",
    "# sets together. \n",
    "X_train = fix_data(X_train)\n",
    "\n",
    "# As stated above, the masker handles the missing features. In this case, we are using correlations \n",
    "# in the dataset to determine the feature groupings. These groups of features are remove or added into \n",
    "# sets together. \n",
    "shap_kws={'masker' : shap.maskers.Partition(X_train.values.astype(float), \n",
    "                                            max_samples=150, clustering=\"correlation\"), \n",
    "           'algorithm' : 'permutation'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4171d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_feature_names = {f: to_display_name(f) for f in features}\n",
    "display_units = {f: to_units(f) for f in features}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fde5128",
   "metadata": {},
   "source": [
    "### SHAP Values for the Highest Tornado Prediction on the Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pred = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "inds = np.argsort(pred)[::-1]\n",
    "\n",
    "\n",
    "ind = inds[10]\n",
    "\n",
    "single_example = X_test.iloc[[ind]].astype(float)\n",
    "\n",
    "explainer = skexplain.ExplainToolkit(('LR', model), X=single_example)\n",
    "contrib_ds = explainer.local_attributions(method='shap', \n",
    "                                           shap_kws = shap_kws,\n",
    "                                          )\n",
    "\n",
    "fig, axes = explainer.plot_contributions(\n",
    "    contrib = contrib_ds, \n",
    "    display_feature_names = display_feature_names, \n",
    "    display_units = display_units,\n",
    "    max_display = 25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0b885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
