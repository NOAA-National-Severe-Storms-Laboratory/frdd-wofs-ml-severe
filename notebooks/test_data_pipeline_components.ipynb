{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71200ef9",
   "metadata": {},
   "source": [
    "## Test the Different Components of the ML Data Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d249d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib,os,sys\n",
    "_base_module_path = '/home/monte.flora/python_packages'\n",
    "modules = ['wofs_ml_severe']\n",
    "paths = [sys.path.append(os.path.join(_base_module_path, m)) for m in modules]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b115978",
   "metadata": {},
   "source": [
    "### 0. Sending an email"
   ]
  },
  {
   "cell_type": "raw",
   "id": "784bf852",
   "metadata": {},
   "source": [
    "## WORKS!!!\n",
    "\n",
    "from wofs_ml_severe.common.emailer import Emailer\n",
    "emailer = Emailer()\n",
    "start_time = emailer.get_start_time()\n",
    "emailer.send_email('Testing the email works', start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0bd9ed",
   "metadata": {},
   "source": [
    "### 1. Ensemble Storm Track Creation \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6aa8c7d3",
   "metadata": {},
   "source": [
    "## WORKS!!\n",
    "\n",
    "# Existing files can be appended\n",
    "# New object ID code has been added. \n",
    "\n",
    "from wofs_ml_severe.data_pipeline.ensemble_track_segmentation import generate_ensemble_track_file\n",
    "from glob import glob\n",
    "import xarray as xr \n",
    "\n",
    "date = '20210504'\n",
    "time = '2300'\n",
    "ncfile = glob(f'/work/mflora/SummaryFiles/{date}/{time}/wofs_30M*')[0]\n",
    "\n",
    "generate_ensemble_track_file(ncfile, debug=True, overwrite=False)\n",
    "\n",
    "ds = xr.load_dataset('wofs_30M_16_20210504_2350_0020.nc')\n",
    "ds.w_up__ensemble_tracks.plot(cmap='tab20')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278c144f",
   "metadata": {},
   "source": [
    "### 2. Extracting ML Features \n",
    "\n",
    "Create Unit test! \n",
    "\n",
    "Adding new ML features \n",
    "1. Ensemble maximum for both spatial and amplitude features [X]\n",
    "2. Conditional amplitude ensemble statistics (i.e., only including ensemble members within a storm)[X]\n",
    "3. Number of ensemble members within an ensemble storm track [X] \n",
    "4. Ensemble avg. of the area of individual storm tracks within an ensemble storm tracks (call it P). Ratio of P to the full ensemble storm area area. Idea: ensemble storm track can be large due to the lack of overlap [X]. \n",
    "7. Dummy variable (binary) if a storm is elevated. Idea: minimum height of dBZ exceeding a threshold [X]\n",
    "8. Okubo-Weiss treated as a minimum variable [X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9ee41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wofs_ml_severe.data_pipeline.ml_data_generator import MLDataGenerator\n",
    "from wofs_ml_severe.data_pipeline.ensemble_track_segmentation import generate_ensemble_track_file\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "def test_feature_extract():\n",
    "        NV, NE, NY, NX = (3,5,300,300)\n",
    "        \n",
    "        # Generate the track file. \n",
    "        file_30M = '/home/monte.flora/python_packages/wofs_ml_severe/tests/test_data/wofs_30M_07_20210504_2205_2235.nc'\n",
    "        track_file = file_30M.replace('30M', 'ENSEMBLETRACKS')\n",
    "        generate_ensemble_track_file(file_30M)\n",
    "\n",
    "        # Create fake data (NV, NE, NY, NX)\n",
    "        ens_data = np.random.normal(size=(NV,NE,NY,NX))\n",
    "        \n",
    "        ds = {}\n",
    "        for typ in ['ens', 'env', 'svr']:\n",
    "            data = {f'{typ}_{i+1}' : (['NE', 'NY', 'NX'], ens_data[i,:,:,:]) for i in range(NV)}\n",
    "\n",
    "            if typ == 'ens':\n",
    "                data['uh_2to5'] = (['NE', 'NY', 'NX'], ens_data[0,:,:,:])\n",
    "                data['ws_80'] = (['NE', 'NY', 'NX'], ens_data[0,:,:,:])\n",
    "                data['hailcast'] = (['NE', 'NY', 'NX'], ens_data[0,:,:,:])\n",
    "            \n",
    "            ds[typ] = xr.Dataset(data)\n",
    "            \n",
    "        \n",
    "        ens_filenames = [f'wofs_ENS_{i:02d}' for i in range(6)]\n",
    "        env_filename = ['wofs_ENV_06']\n",
    "        svr_filename = ['wofs_SVR_06']\n",
    "        \n",
    "        all_filenames = ens_filenames + env_filename + svr_filename\n",
    "        \n",
    "        files_to_load = [{'track_file' : track_file,\n",
    "                         'ens_file' : ens_filenames,\n",
    "                         'env_file' : env_filename[0],\n",
    "                         'svr_file' : svr_filename[0],\n",
    "                        }]\n",
    "                         \n",
    "        for f in all_filenames:\n",
    "            typ = f.split('_')[1].lower()\n",
    "            ds[typ].to_netcdf(f) \n",
    "        \n",
    "        data_generator = MLDataGenerator(files_to_load, TEMP=False, \n",
    "                ml_config_path='/home/monte.flora/python_packages/wofs_ml_severe/tests/test_data/ml_config.yml')\n",
    "\n",
    "        data_generator(runtype='rto') \n",
    "        \n",
    "        # Checks that MLDATA file has been created. \n",
    "        # (optional) check the len(data) == n_objects. \n",
    "        self.assertIsFile(track_file.replace('ENSEMBLETRACKS', 'MLDATA').replace('.nc', '.feather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ecaca7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving /home/monte.flora/python_packages/wofs_ml_severe/tests/test_data/wofs_ENSEMBLETRACKS_07_20210504_2205_2235.nc...\n",
      "dict_keys(['ens', 'env', 'svr']) ens wofs_ENS_00\n",
      "dict_keys(['ens', 'env', 'svr']) ens wofs_ENS_01\n",
      "dict_keys(['ens', 'env', 'svr']) ens wofs_ENS_02\n",
      "dict_keys(['ens', 'env', 'svr']) ens wofs_ENS_03\n",
      "dict_keys(['ens', 'env', 'svr']) ens wofs_ENS_04\n",
      "dict_keys(['ens', 'env', 'svr']) ens wofs_ENS_05\n",
      "dict_keys(['ens', 'env', 'svr']) env wofs_ENV_06\n",
      "dict_keys(['ens', 'env', 'svr']) svr wofs_SVR_06\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'xlat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ai2es/lib/python3.8/site-packages/xarray/core/dataset.py:1359\u001b[0m, in \u001b[0;36mDataset._copy_listed\u001b[0;34m(self, names)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1359\u001b[0m     variables[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'xlat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_feature_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mtest_feature_extract\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     ds[typ]\u001b[38;5;241m.\u001b[39mto_netcdf(f) \n\u001b[1;32m     44\u001b[0m data_generator \u001b[38;5;241m=\u001b[39m MLDataGenerator(files_to_load, TEMP\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     45\u001b[0m         ml_config_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/monte.flora/python_packages/wofs_ml_severe/tests/test_data/ml_config.yml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m \u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruntype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Checks that MLDATA file has been created. \u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# (optional) check the len(data) == n_objects. \u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massertIsFile(track_file\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mENSEMBLETRACKS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLDATA\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.feather\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/python_packages/wofs_ml_severe/wofs_ml_severe/data_pipeline/ml_data_generator.py:120\u001b[0m, in \u001b[0;36mMLDataGenerator.__call__\u001b[0;34m(self, n_processors, runtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m     run_parallel_realtime(\n\u001b[1;32m    114\u001b[0m     func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker,\n\u001b[1;32m    115\u001b[0m     nprocs_to_use\u001b[38;5;241m=\u001b[39mn_processors,\n\u001b[1;32m    116\u001b[0m     iterator\u001b[38;5;241m=\u001b[39mto_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiles_to_load),\n\u001b[1;32m    117\u001b[0m     rtype\u001b[38;5;241m=\u001b[39mruntype,)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m### Josh: if we are only loading one set of files, we don't need the Pool spinup  \u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles_to_load\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_packages/wofs_ml_severe/wofs_ml_severe/data_pipeline/ml_data_generator.py:125\u001b[0m, in \u001b[0;36mMLDataGenerator._worker\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_worker\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124;03m\"\"\"Worker function for multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_ml_severe_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mensemble_track_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrack_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m                        \u001b[49m\u001b[43menv_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menv_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msvr_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msvr_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mens_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mens_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m                       \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_packages/wofs_ml_severe/wofs_ml_severe/data_pipeline/ml_data_generator.py:267\u001b[0m, in \u001b[0;36mMLDataGenerator.generate_ml_severe_files\u001b[0;34m(self, ensemble_track_file, env_file, svr_file, ens_files)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_there_an_object(storm_objects):\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m# Load ENV file\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     ds_env \u001b[38;5;241m=\u001b[39m open_dataset(env_file, decode_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 267\u001b[0m     ds_subset \u001b[38;5;241m=\u001b[39m \u001b[43mds_env\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxlat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxlon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhgt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    268\u001b[0m     env_data \u001b[38;5;241m=\u001b[39m {var: ds_env[var]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mml_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mENV_VARS\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTEMP: \n\u001b[1;32m    271\u001b[0m         \u001b[38;5;66;03m# Convert lapse rate from C/KM back to C \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai2es/lib/python3.8/site-packages/xarray/core/dataset.py:1500\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_dataarray(key)\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_copy_listed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai2es/lib/python3.8/site-packages/xarray/core/dataset.py:1361\u001b[0m, in \u001b[0;36mDataset._copy_listed\u001b[0;34m(self, names)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     variables[name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables[name]\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m-> 1361\u001b[0m     ref_name, var_name, var \u001b[38;5;241m=\u001b[39m \u001b[43m_get_virtual_variable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_level_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1364\u001b[0m     variables[var_name] \u001b[38;5;241m=\u001b[39m var\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ref_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coord_names \u001b[38;5;129;01mor\u001b[39;00m ref_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims:\n",
      "File \u001b[0;32m~/miniconda3/envs/ai2es/lib/python3.8/site-packages/xarray/core/dataset.py:169\u001b[0m, in \u001b[0;36m_get_virtual_variable\u001b[0;34m(variables, key, level_vars, dim_sizes)\u001b[0m\n\u001b[1;32m    167\u001b[0m     ref_var \u001b[38;5;241m=\u001b[39m dim_var\u001b[38;5;241m.\u001b[39mto_index_variable()\u001b[38;5;241m.\u001b[39mget_level_variable(ref_name)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     ref_var \u001b[38;5;241m=\u001b[39m \u001b[43mvariables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mref_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     virtual_var \u001b[38;5;241m=\u001b[39m ref_var\n",
      "\u001b[0;31mKeyError\u001b[0m: 'xlat'"
     ]
    }
   ],
   "source": [
    "test_feature_extract()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e250aae6",
   "metadata": {},
   "source": [
    "from wofs_ml_severe.data_pipeline.ml_data_generator import MLDataGenerator\n",
    "from wofs_ml_severe.data_pipeline.ensemble_track_segmentation import generate_ensemble_track_file\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "indir = '/work/mflora/SummaryFiles/20210504/2300'\n",
    "\n",
    "t = 3\n",
    "delta_time_step = 6\n",
    "\n",
    "files_to_load = []\n",
    "track_file = glob(join(indir, f'wofs_ENSEMBLETRACKS_{t+delta_time_step:02d}*'))[0]\n",
    "env_file = glob(join(indir, f'wofs_ENV_{t:02d}*'))[0]\n",
    "svr_file = env_file.replace('ENV', 'SVR')\n",
    "ens_files = [glob(join(indir, f'wofs_ENS_{_t:02d}*'))[0] for _t in range(t, t+delta_time_step+1)]                \n",
    "files_to_load.append( {'track_file': track_file, \n",
    "                         'ens_file' : ens_files, \n",
    "                         'env_file'  : env_file, \n",
    "                         'svr_file'  : svr_file,      \n",
    "                        }) \n",
    "\n",
    "ncfile = track_file.replace('ENSEMBLETRACKS', '30M')\n",
    "generate_ensemble_track_file(ncfile, debug=False, overwrite=True)\n",
    "\n",
    "ml_config_path = os.path.join(pathlib.Path(os.getcwd()).parent.resolve(), \n",
    "                              'wofs_ml_severe/conf/ml_config_retro_test.yml')\n",
    "\n",
    "data_generator = MLDataGenerator(files_to_load, TEMP=False, retro=True, ml_config_path=ml_config_path, debug=True)\n",
    "\n",
    "data_generator(n_processors=1, \n",
    "                  runtype='rto',\n",
    "                  predict=False,\n",
    "                  explain=False\n",
    "                 ) \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_feather('wofs_MLDATA_09_20210504_2315_2345.feather')\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb41fb",
   "metadata": {},
   "source": [
    "### 3. Matching Storm Tracks to ML Features "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d664f414",
   "metadata": {},
   "source": [
    "## WORKS!!\n",
    "\n",
    "from monte_python.object_matching import match_to_lsrs, ObjectMatcher\n",
    "from WoF_post.wofs.verification.lsrs.get_storm_reports import StormReports\n",
    "from WoF_post.wofs.plotting.util import decompose_file_path\n",
    "import xarray as xr \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "\n",
    "def get_reports(ncfile, \n",
    "                reports_path='/work/mflora/LSRS/STORM_EVENTS_2017-2022.csv', \n",
    "                report_type='NOAA'):\n",
    "    \"\"\" Get the storm reports for the forecast period. \"\"\"\n",
    "    # Determine the initial time from the ncfile \n",
    "    comps = decompose_file_path(ncfile)\n",
    "    init_time = comps['VALID_DATE']+comps['VALID_TIME']\n",
    "    report = StormReports(\n",
    "            reports_path,\n",
    "            report_type,\n",
    "            init_time, \n",
    "            forecast_length=30,\n",
    "            err_window=15, \n",
    "            )\n",
    " \n",
    "    ds = xr.load_dataset(ncfile)\n",
    "        \n",
    "    try:\n",
    "        grid_ds = report.to_grid(dataset=ds)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        #self.logger('info', f'Unable to process storm reports for {ncfile}!')\n",
    "        #self.logger('error', e, exc_info=True) \n",
    "    \n",
    "    return grid_ds\n",
    "\n",
    "min_dists = [0,5,10,20,30]\n",
    "\n",
    "def match_tracks_to_reports(track_file):\n",
    "    \"\"\"\n",
    "    Match the ensemble storm tracks to the gridded LSRs. \n",
    "    Outputs a dataframe of targets for the MLDATA-based summary files.\n",
    "    \n",
    "    Multiple matching minimum matching distances are used. \n",
    "    \"\"\"\n",
    "    tracks_ds = xr.load_dataset(track_file, decode_times=False)\n",
    "    tracks = tracks_ds['w_up__ensemble_tracks'].values\n",
    "    ens_probs = tracks_ds['w_up__ensemble_probabilities'].values\n",
    "    \n",
    "    labels = np.unique(tracks)[1:]\n",
    "    storm_data_ds = get_reports(track_file)\n",
    "    \n",
    "    target_vars = [v for v in storm_data_ds.data_vars if 'severe' in v] \n",
    "    \n",
    "    if len(target_vars) == 0:\n",
    "        return None \n",
    "    \n",
    "    targets_data = {}\n",
    "            \n",
    "    for var in target_vars:\n",
    "        target = storm_data_ds[var].values\n",
    "        for min_d in min_dists:\n",
    "            obj_match = ObjectMatcher(min_dist_max=min_d,\n",
    "                                      score_thresh = 0.2,\n",
    "                                      time_max=0,\n",
    "                                      one_to_one = False, match_to_reports=True)\n",
    "                        \n",
    "            matched_tracks, _ , _ = obj_match.match_objects(object_set_a=tracks, \n",
    "                                                            object_set_b=target, input_a=ens_probs)\n",
    "\n",
    "                        \n",
    "            # Create target column \n",
    "            targets_data[f\"{var}_{min_d*3}km_obj_match\"] = [1 if label in matched_tracks \n",
    "                                                                     else 0 for label in labels]\n",
    "            \n",
    "    df = pd.DataFrame(targets_data)\n",
    "    target_file = track_file.replace('ENSEMBLETRACKS', 'MLTARGETS').replace('.nc', '.feather')\n",
    "            \n",
    "    #self.logger('debug', f'Saving {target_file}...')\n",
    "    target_file = os.path.basename(target_file)\n",
    "            \n",
    "    df.to_feather(target_file)\n",
    "\n",
    "    return target_file    \n",
    "\n",
    "from glob import glob\n",
    "track_file = glob('/work/mflora/SummaryFiles/20210517/2300/wofs_ENSEMBLETRACKS_07*')[0]\n",
    "match_tracks_to_reports(track_file)\n",
    "pd.read_feather('wofs_MLTARGETS_07_20210517_2305_2335.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba432c",
   "metadata": {},
   "source": [
    "### 4. Concatenate into single dataframe "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
