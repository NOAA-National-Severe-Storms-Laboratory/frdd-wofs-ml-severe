{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470692d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the parent directory to path so that \n",
    "# skexplain can be imported without being explicitly\n",
    "import os,sys\n",
    "path = os.path.dirname(os.getcwd())\n",
    "sys.path.append(path)\n",
    "\n",
    "_base_module_path = '/home/monte.flora/python_packages/master/WoF_post'\n",
    "sys.path.append(_base_module_path)\n",
    "\n",
    "from wofs_ml_severe.data_pipeline.storm_based_feature_extracter import StormBasedFeatureExtracter\n",
    "from wofs.post.utils import load_yaml\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import monte_python\n",
    "import xarray as xr \n",
    "import glob\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ffe5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_config_dict = load_yaml(os.path.join(path,'wofs_ml_severe/conf','test_config.yml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d3a9c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracter = StormBasedFeatureExtracter(ml_config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9330f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.load_dataset('test_ENSEMBLETRACKS.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a46a9f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the spatial statistics. \n",
    "storm_objects = ds.label_img.values\n",
    "intensity_img = ds.intensity_img.values\n",
    "\n",
    "object_props_df = extracter.get_object_properties(storm_objects, intensity_img)\n",
    "labels = object_props_df['label'].values\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c98c40ef",
   "metadata": {},
   "source": [
    "# Extract the spatial statistics. \n",
    "storm_objects = ds.label_img.values\n",
    "intensity_img = ds.intensity_img.values\n",
    "\n",
    "object_props_df = extracter.get_object_properties(storm_objects, intensity_img)\n",
    "labels = object_props_df['label'].values\n",
    "\n",
    "# Build a fake dataset\n",
    "data = np.zeros(storm_objects.shape)\n",
    "fake_data = [1,3,5,7,9]\n",
    "for d, label in zip(fake_data, labels):\n",
    "    data[storm_objects==label] = d\n",
    "\n",
    "ensemble_data = {'ens_var1' : data, \n",
    "                 'ens_var2' : data, \n",
    "                 'env_var3' : data, \n",
    "                 'env_var4' : data,\n",
    "                }\n",
    "\n",
    "df_spatial = extracter.extract_spatial_features_from_object( \n",
    "                ensemble_data, storm_objects, labels)\n",
    "\n",
    "# This should be true! \n",
    "df_spatial.iloc[:,0].values == [fake_data]*5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a46a61e1",
   "metadata": {},
   "source": [
    "# Extract the amplitude statistics (only marginal statistics). \n",
    "\n",
    "# Build a fake dataset (NE, NY, NX)\n",
    "NE = 5\n",
    "data = np.zeros((NE, storm_objects.shape[0], storm_objects.shape[1]))\n",
    "fake_data = [1,3,5,7,9]\n",
    "for i in range(NE):\n",
    "    for d, label in zip(fake_data, labels):\n",
    "        data[i, storm_objects==label] = d+i\n",
    "    \n",
    "storm_data_time_composite = {'ens_var1__time_max' : data}\n",
    "    \n",
    "df_amp = extracter.extract_amplitude_features_from_object( \n",
    "                storm_data_time_composite, storm_objects, labels, cond_var=None, \n",
    "                cond_var_thresh = None)\n",
    "\n",
    "vals = np.unique(data[:,storm_objects==1])\n",
    "true_arr = [np.std(vals, ddof=1), np.mean(vals), np.max(vals)]\n",
    "\n",
    "# This should be true! \n",
    "df_amp.iloc[0,:].values == true_arr\n",
    "\n",
    "true_names = ['ens_var1__time_max__amp_ens_std', \n",
    "              'ens_var1__time_max__amp_ens_mean',\n",
    "              'ens_var1__time_max__amp_ens_max']\n",
    "\n",
    "# This should be true! \n",
    "df_amp.columns.values == true_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3c079c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features=10 n_vars=2 n_stats=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  True])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the amplitude statistics (conditional statistics). \n",
    "\n",
    "# Build a fake dataset (NE, NY, NX)\n",
    "NE = 5\n",
    "data = np.zeros((NE, storm_objects.shape[0], storm_objects.shape[1]))\n",
    "fake_data = [1,3,5,7,9]\n",
    "for i in range(NE):\n",
    "    for d, label in zip(fake_data, labels):\n",
    "        data[i, storm_objects==label] = d+i\n",
    "    \n",
    "# Build a conditional variable \n",
    "cond_data = np.zeros((NE, storm_objects.shape[0], storm_objects.shape[1]))\n",
    "for i in range(NE):\n",
    "    if i > 2:\n",
    "        for label in labels:\n",
    "            cond_data[i, storm_objects==label] = 2\n",
    "    \n",
    "storm_data_time_composite = {'ens_var1__time_max' : data, \n",
    "                             'cond_var' : cond_data,\n",
    "                            }\n",
    "    \n",
    "df_amp = extracter.extract_amplitude_features_from_object( \n",
    "                storm_data_time_composite, storm_objects, labels, cond_var='cond_var', \n",
    "                cond_var_thresh = 1)\n",
    "\n",
    "vals = np.unique(data[:,storm_objects==1])\n",
    "true_arr = [np.std(vals, ddof=1), np.mean(vals), np.max(vals)]\n",
    "\n",
    "# This should be true! \n",
    "# This ensures that though we are computing the conditional variables\n",
    "# we are still correctly computing the marginal variables. \n",
    "cols = ['ens_var1__time_max__amp_ens_std', 'ens_var1__time_max__amp_ens_mean', 'ens_var1__time_max__amp_ens_max' ]\n",
    "np.round(df_amp.loc[0,cols].values,2) - np.round(true_arr,2) < 1e-7\n",
    "\n",
    "# Computed the conditional statistics correctly? \n",
    "vals = np.unique(data[:,storm_objects==1])[3:]\n",
    "stats = [np.std(vals, ddof=1), np.mean(vals)]\n",
    "\n",
    "cols = [f'{c}__cond' for c in cols if 'ens_max' not in c ]\n",
    "np.round(df_amp.loc[0,cols].values,2) - np.round(stats,2) < 1e-7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
