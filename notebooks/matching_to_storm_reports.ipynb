{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b60fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "from os.path import join\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, '/home/monte.flora/python_packages/MontePython/')\n",
    "\n",
    "sys.path.append('/home/monte.flora/python_packages/WoF_post')\n",
    "from monte_python.object_matching import match_to_lsrs, ObjectMatcher\n",
    "from wofs.verification.lsrs.get_storm_reports import StormReports\n",
    "from wofs.plotting.util import decompose_file_path\n",
    "from skimage.measure import regionprops\n",
    "from glob import glob\n",
    "from scipy.ndimage import maximum_filter, gaussian_filter, minimum_filter\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/monte.flora/python_packages/MontePython')\n",
    "import monte_python\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bdcadce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(data):\n",
    "    return np.ma.masked_where(data==0, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fda017ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reports_to_grid(ncfile, \n",
    "                    reports_path='/work/mflora/LSRS/STORM_EVENTS_2017-2022.csv', \n",
    "                report_type='NOAA'):\n",
    "    comps = decompose_file_path(ncfile)\n",
    "    init_time = comps['VALID_DATE']+comps['VALID_TIME']\n",
    "    report = StormReports(\n",
    "            reports_path,\n",
    "            report_type,\n",
    "            init_time, \n",
    "            forecast_length=30,\n",
    "            err_window=15,             \n",
    "            )\n",
    " \n",
    "    ds = xr.load_dataset(ncfile)\n",
    "    grid_ds = report.to_grid(dataset=ds)\n",
    "    lsr_points = report.get_points(dataset=ds)\n",
    "\n",
    "    return grid_ds, lsr_points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240fef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matched(data, matched_labels):\n",
    "    matched = np.zeros(data.shape)\n",
    "    \n",
    "    unique_labels = np.unique(data)[1:]\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        if label in matched_labels:\n",
    "            matched[data==label] = 1.0\n",
    "        else:\n",
    "            matched[data==label] = -1.0\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be40f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_centroid(x, y, ax, object_props, storm_modes=None, converter=None):\n",
    "    \"\"\"Place object label on object's centroid\"\"\"\n",
    "    for region in object_props:\n",
    "        x_cent,y_cent = region.centroid\n",
    "        x_cent=int(x_cent)\n",
    "        y_cent=int(y_cent)\n",
    "        xx, yy = x[x_cent,y_cent], y[x_cent,y_cent]\n",
    "        \n",
    "        if storm_modes is None:\n",
    "            fontsize = 6.5 if region.label >= 10 else 8\n",
    "            txt = region.label\n",
    "        else:\n",
    "            fontsize=4\n",
    "            coords = region.coords\n",
    "            ind = int(np.max(storm_modes[coords[:,0], coords[:,1]]))\n",
    "            txt = converter[ind] \n",
    "          \n",
    "        ax.text(xx,yy,\n",
    "                    txt,\n",
    "                    fontsize=fontsize,\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    color = 'k'\n",
    "                    )    \n",
    "\n",
    "def plot_storm_labels(x, y, labels, ax=None, alpha=1.0):\n",
    "    \"\"\" Plot Storm Labels \"\"\"\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(figsize=(5, 4), dpi=150, facecolor='w', edgecolor='k')\n",
    "    \n",
    "    label_props = regionprops(labels, labels)\n",
    "    \n",
    "    labels = np.ma.masked_where(labels==0, labels)\n",
    "    c = ax.pcolormesh(x, y, labels, cmap='tab20', vmin=1, vmax=np.max(labels), alpha=alpha, shading='auto')\n",
    "    ax.tick_params(axis='both', bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.grid(alpha=0.5, ls='dashed')\n",
    "    \n",
    "    label_centroid(x, y, ax, label_props) \n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ba8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_id(input_data, remove_low=True):\n",
    "    \n",
    "    param_set = [ {'min_thresh': 0,\n",
    "                   'max_thresh': 100,\n",
    "                   'data_increment': 1,\n",
    "                   'delta': 0,\n",
    "                   'area_threshold': 800,\n",
    "                   'dist_btw_objects': 125 },\n",
    "             \n",
    "             {'min_thresh': 30,\n",
    "                   'max_thresh': 100,\n",
    "                   'data_increment': 1,\n",
    "                   'delta': 0,\n",
    "                   'area_threshold': 400,\n",
    "                   'dist_btw_objects': 30 },\n",
    "                 \n",
    "             {'min_thresh': 50,\n",
    "                   'max_thresh': 100,\n",
    "                   'data_increment': 1,\n",
    "                   'delta': 0,\n",
    "                   'area_threshold': 250,\n",
    "                   'dist_btw_objects': 25 },    \n",
    "                 \n",
    "            ]\n",
    "\n",
    "    params = {'params': param_set }\n",
    "\n",
    "    # Less than 2/18 = 0.11, 1/18 = 0.055\n",
    "    new_input_data = np.copy(input_data)\n",
    "    #if remove_low:\n",
    "    #    new_input_data[input_data<=0.12] = 0\n",
    "\n",
    "    new_input_data = maximum_filter(new_input_data, size=4)\n",
    "    if remove_low:\n",
    "        new_input_data[input_data<=0.12] = 0\n",
    "    \n",
    "    new_input_data = gaussian_filter(new_input_data, 1.5)*100\n",
    "\n",
    "    storm_labels, new_object_props = monte_python.label(  input_data = new_input_data, \n",
    "                       method ='iterative_watershed', \n",
    "                       return_object_properties=True, \n",
    "                       params = params,  \n",
    "                       )\n",
    "    \n",
    "    # Reduce the object size due to the maximum filter and gaussian filter \n",
    "    idx = np.where(input_data==0)\n",
    "    storm_labels[idx] = 0\n",
    "    \n",
    "    #storm_labels = minimum_filter(storm_labels, size=3)\n",
    "    new_object_props = regionprops(storm_labels, storm_labels)\n",
    "    \n",
    "    return storm_labels, new_input_data, new_object_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30db2fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def animate(i):\n",
    "    fname = fnames[i]\n",
    "    for ax in axes.flat:\n",
    "        ax.clear()\n",
    "    \n",
    "    # Adding metadata to the plot. \n",
    "    axes[0,0].annotate(f'Matching to {var}; Report size has been exaggerated for easier identification',\n",
    "                    (0.05, 1.05), xycoords='axes fraction')\n",
    "    \n",
    "    axes[0,0].annotate(fname,\n",
    "                    (0.05, 1.02), xycoords='axes fraction')\n",
    "    \n",
    "    axes[0,0].annotate(f'Generated using\\n{os.getcwd()}/matching_to_storm_reports.ipynb',\n",
    "                    (0.05, 0.05), xycoords='axes fraction', fontsize=6)\n",
    "    \n",
    "    # Load the ensemble tracks and the probs the tracks were generated from.\n",
    "    ds = xr.load_dataset(fname)\n",
    "    \n",
    "    tracks = ds['w_up__ensemble_tracks'].values\n",
    "    probs = ds['w_up__ensemble_probabilities'].values\n",
    "    \n",
    "    tracks,_,_ = new_id(probs)\n",
    "    \n",
    "    labels = np.unique(tracks)[1:]\n",
    "    storm_data_ds, lsr_points = reports_to_grid(fname)\n",
    "\n",
    "    target = storm_data_ds[var].values\n",
    "    reports = mask(storm_data_ds[var])\n",
    "    reports[reports>0] = 1\n",
    "    \n",
    "    # Perform different object matching.\n",
    "    matched_tracks_set=[]\n",
    "    #dists = [10, 15, 20, 30]\n",
    "    \n",
    "    # 9 , 15, 27, 36\n",
    "    dists = [3,5,9,12]\n",
    "    for dist in dists:\n",
    "        obj_match = ObjectMatcher(min_dist_max=dist,\n",
    "                                      cent_dist_max=cent_dist,\n",
    "                                      time_max=0,\n",
    "                                      score_thresh = 0.2,\n",
    "                                      one_to_one = False, \n",
    "                                     match_to_reports=True)\n",
    "\n",
    "        matched_tracks, _, _ = obj_match.match(object_set_a=tracks, object_set_b=target, input_a=probs)\n",
    "        matched_arr = to_matched(tracks, matched_tracks)\n",
    "        matched_tracks_set.append(matched_arr)\n",
    "    \n",
    "    # Matching based on if the report falls within the track (like the original paper).\n",
    "    object_props = regionprops(tracks, tracks)    \n",
    "    match_dict = match_to_lsrs(object_props, lsr_points[var], dist_to_lsr=1)\n",
    "\n",
    "    matched_tracks = [l for l in labels if match_dict[l] == 1.0]\n",
    "    \n",
    "    matched_arr = to_matched(tracks, matched_tracks)\n",
    "    matched_tracks_set.append(matched_arr)\n",
    "    \n",
    "    x,y = np.meshgrid(np.arange(len(tracks)), np.arange(len(tracks)))\n",
    "    \n",
    "    # Upper left hand. Ensemble storm tracks and the underlying probs. \n",
    "    axes[0,0].contourf(x,y,mask(probs), cmap='jet', alpha=0.9)\n",
    "    plot_storm_labels(x,y,tracks, ax=axes[0,0], alpha=0.5)   \n",
    "    \n",
    "    # Upper right hand.\n",
    "    for i, (ax, data) in enumerate(zip(axes.flat[1:], matched_tracks_set)):\n",
    "        if i < 4:\n",
    "            #ax.annotate(f'Min Dist: {dists[i]*3} km, Cent Dist: {cent_dist*3} km',\n",
    "            #        (0.05, 0.05), xycoords='axes fraction', fontsize=7)\n",
    "            ax.annotate(f'Min Dist: {dists[i]*3} km  Cent. Dist : {cent_dist*3}km',\n",
    "                    (0.05, 0.05), xycoords='axes fraction', fontsize=8)\n",
    "            \n",
    "        else:\n",
    "            ax.annotate(f'Report falls within track bdry',\n",
    "                    (0.05, 0.05), xycoords='axes fraction')\n",
    "        ax.contourf(x, y, mask(data), cmap='seismic', levels=[-1,0,1], alpha=0.3) \n",
    "        ax.contourf(x, y, mask(maximum_filter(reports,5)), colors='k', alpha=0.9) \n",
    "        #ax.set_xlim([175, 250])\n",
    "        #ax.set_ylim([50, 100])\n",
    "        ax.grid()\n",
    "    \n",
    "    \n",
    "fig, axes = plt.subplots(dpi=170, figsize=(12,10), ncols=3, nrows=2)\n",
    "\n",
    "# 20210526, 20210513, 20210504, 20210517, 20180502 (torn), 20180518 (torn), 20200507 (hail)\n",
    "# 20200504 (hail)\n",
    "\n",
    "date = '20210517'\n",
    "init_time = '2300'\n",
    "save_gif = False\n",
    "var = 'hail_sig_severe'\n",
    "\n",
    "cent_dist = 30\n",
    "colors = {'wind_severe' : 'b', 'hail_severe' : 'g', 'tornado_severe' : 'r'}\n",
    "path = f'/work/mflora/SummaryFiles/{date}/{init_time}'\n",
    "fnames = glob(join(path, 'wofs_ENSEMBLETRACKS_*'))\n",
    "\n",
    "fnames.sort()\n",
    "fnames = fnames[:12]\n",
    "    \n",
    "# call the animator. blit=True means only re-draw the parts that have changed.\n",
    "#plt.tight_layout()\n",
    "anim = FuncAnimation(fig, animate, frames=len(fnames), interval=200, repeat=True, blit=False)\n",
    "HTML(anim.to_jshtml())\n",
    "#anim.save(f'matched_to_reports_{date}_{init_time}_{var}.gif', writer='pillow', fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a5676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
